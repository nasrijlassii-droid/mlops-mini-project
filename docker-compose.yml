 #version: "3.9"
services:
  # -----------------------------------------------------------------
  # 1️⃣ MLflow tracking server
  # -----------------------------------------------------------------
  mlflow:
    image: mlflow/mlflow:2.12.2          # ← version officielle qui existe
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      - BACKEND_STORE_URI=sqlite:////mlflow/mlflow.db
      - DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri ${BACKEND_STORE_URI}
      --default-artifact-root ${DEFAULT_ARTIFACT_ROOT}
    volumes:
      - ./mlflow:/mlflow               # persistance des DB + artefacts

  # -----------------------------------------------------------------
  # 2️⃣ FastAPI inference API
  # -----------------------------------------------------------------
  api:
    build: .
    container_name: iris_api
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
    depends_on:
      - mlflow
    volumes:
      - ./mlflow:/mlflow
      - ./src:/app/src
    command: >
      uvicorn src.api:app --host 0.0.0.0 --port 8000

  # -----------------------------------------------------------------
  # 3️⃣ Trainer (exécute le pipeline ZenML à la demande)
  # -----------------------------------------------------------------
  trainer:
    build: .
    container_name: iris_trainer
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
    depends_on:
      - mlflow
    volumes:
      - ./mlflow:/mlflow
      - ./src:/app/src
      - ./data:/app/data
      - ./.zen:/app/.zen
    entrypoint: ["/bin/bash","-c"]
    # Lancer le pipeline : docker compose run trainer ./run_pipeline.sh
