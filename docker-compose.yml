 #version: "3.9"

services:
  # -----------------------------------------------------------------
  # 1️⃣ MLflow tracking server
  # -----------------------------------------------------------------
  mlflow:
    build: .                         # utilise le Dockerfile du projet
    container_name: mlflow
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
    ports:
      - "5000:5000"
    environment:
      # Ces variables seront lues par les autres services (API, trainer)
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - ./mlflow:/mlflow            # persistance des métadonnées et artefacts

  # -----------------------------------------------------------------
  # 2️⃣ FastAPI inference API
  # -----------------------------------------------------------------
  api:
    build: .
    container_name: iris_api
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
    depends_on:
      - mlflow
    volumes:
      - ./mlflow:/mlflow
      - ./src:/app/src
    command: >
      uvicorn src.api:app --host 0.0.0.0 --port 8000

  # -----------------------------------------------------------------
  # 3️⃣ Trainer (exécute le pipeline ZenML à la demande)
  # -----------------------------------------------------------------
  trainer:
    build: .
    container_name: iris_trainer
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
    depends_on:
      - mlflow
    volumes:
      - ./mlflow:/mlflow
      - ./src:/app/src
      - ./data:/app/data
      - ./.zen:/app/.zen
    entrypoint: ["/bin/bash","-c"]
    # Lancer le pipeline : docker compose run trainer ./run_pipeline.sh
